# QLearner_BlackScholes
A Python implementation of the off-policy algorithm well known as the Q-Learning algorithm. In order to transform the original problem of pricing a Black Scholes based derivative, we stray from the academic continuous-time limit and use a discretized version of the classic Black Scholes model in order to construct a risk-neutral Markov Decision Process. Here, the option price of the MDP is an optimal Q-function. Pricing and hedging an option when the stock dynamics, such as the volatility, are unknown is now possible through the use of the Q-Learning algorithm. The model itself does not make any guesses or assumptions about the structure of the data it is given, and is guaranteed to asymptotically converge to the optimal solution given enough data and time. As a result, this suggests that the RL environment could be used to provide more optimal pricing of financial derivatives in a practical real world setting.
